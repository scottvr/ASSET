# -*- coding: utf-8 -*-
"""battery-tests-20241209.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kOUsPwazUN6DBgcorOG21vAaTn3bJIV3
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# 
# import locale
# import os
# from pathlib import Path
# from datetime import datetime
# 
# def set_utf8_locale():
#     """Sets the locale to UTF-8."""
#     try:
#         locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
#         return
#     except locale.Error:
#         try:
#             locale.setlocale(locale.LC_ALL, 'C.UTF-8')
#             return
#         except locale.Error:
#             print("Warning: Could not set locale to UTF-8. Some operations may not work correctly.")
# 
# # Set locale first
# set_utf8_locale()
# 
# # Core dependencies
# %pip install librosa numpy pillow torch diffusers matplotlib spleeter
# !pip3 install -U xformers --index-url https://download.pytorch.org/whl/cu124
# %pip install torchvision -U spleeter
# 
# # Additional dependencies for enhanced spectral analysis
# %pip install soundfile scipy pandas networkx
# 
# # Install stemprover
# !pip install git+https://github.com/scottvr/ASSET
# 
# # Real-ESRGAN setup (for future enhancement)
# !git clone https://github.com/xinntao/Real-ESRGAN.git
# %cd Real-ESRGAN
# !pip install basicsr facexlib gfpgan
# !pip install -r requirements.txt
# !python setup.py develop
# %cd /content
# 
# # Mount Google Drive and set up directory structure
# from google.colab import drive
# drive.mount('/content/drive')
# 
# # Create organized directory structure
# def setup_battery_test_directories(base_dir: str = '/content/drive/MyDrive/stemtest'):
#     """Creates and returns organized directory structure for battery tests"""
#     timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# 
#     dirs = {
#         'base': Path(base_dir),
#         'stems': Path(base_dir) / 'stems',
#         'results': Path(base_dir) / 'results' / timestamp,
#         'segments': Path(base_dir) / 'results' / timestamp / 'segments',
#         'analysis': Path(base_dir) / 'results' / timestamp / 'analysis',
#         'plots': Path(base_dir) / 'results' / timestamp / 'plots'
#     }
# 
#     # Create all directories
#     for dir_path in dirs.values():
#         dir_path.mkdir(parents=True, exist_ok=True)
# 
#     return dirs
# 
# # Set up directories and save paths for easy access
# dirs = setup_battery_test_directories()
# 
# # Verify stem files
# expected_stems = {
#     'vocal_l': 'track-09.wav',
#     'vocal_r': 'track-10.wav',
#     'accompaniment_l': 'track-07.wav',
#     'accompaniment_r': 'track-08.wav'
# }
# 
# print("\nChecking for required stem files...")
# missing_stems = []
# for stem_type, filename in expected_stems.items():
#     stem_path = dirs['stems'] / filename
#     if not stem_path.exists():
#         missing_stems.append(filename)
#         print(f"Missing: {filename}")
#     else:
#         print(f"Found: {filename}")
# 
# if missing_stems:
#     print("\nWARNING: Some stem files are missing. Please ensure all required files are in the stems directory:")
#     print(f"{dirs['stems']}")
# else:
#     print("\nAll required stem files found!")
# 
# print("\nDirectory structure created:")
# for name, path in dirs.items():
#     print(f"{name}: {path}")

from pathlib import Path
from datetime import datetime
import json
import numpy as np
from dataclasses import dataclass, asdict

from stemprover import SpleeterSeparator, SpectralAnalyzer, ProcessingConfig
from stemprover.analysis.selection.segment_finder import find_best_segments, FoundSegment
from stemprover.types import DEFAULT_FREQUENCY_BANDS
from stemprover.core.audio import AudioSegment
from stemprover.io.audio import load_audio_file

@dataclass
class TimeRange:
    start: float
    end: float

@dataclass
class SegmentAnalysis:
    time_range: TimeRange
    metrics: FoundSegment
    spectral_analysis: dict

def run_enhanced_battery_test(
    vocal_left_path: Path,
    vocal_right_path: Path,
    accompaniment_left_path: Path,
    accompaniment_right_path: Path,
    output_base: str = "enhanced_battery_test",
    full_duration: float = 90.0,  # Full song duration
    vocal_start: float = 30.0,    # Where vocals begin
    segment_length: float = 5.0,   # Length of each segment in seconds
    segment_hop: float = 2.5,      # Hop size between segments in seconds
    top_k: int = 5                 # Number of best segments to select
):
    """Enhanced battery test incorporating segment analysis for training pair generation"""

    # Create timestamped output directory
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path(output_base) / timestamp
    output_dir.mkdir(parents=True, exist_ok=True)

    # Initialize components
    config = ProcessingConfig(
        sample_rate=44100,
        n_fft=2048,
        hop_length=512
    )

    separator = SpleeterSeparator(str(output_dir / "separation"))
    analyzer = SpectralAnalyzer(
        output_dir / "analysis",
        config=config,
        frequency_bands=DEFAULT_FREQUENCY_BANDS
    )

    try:
        # Load audio files into AudioSegment objects
        vocal_l, sr = load_audio_file(vocal_left_path, mono=True)
        vocal_r, _ = load_audio_file(vocal_right_path, mono=True)
        acc_l, _ = load_audio_file(accompaniment_left_path, mono=True)
        acc_r, _ = load_audio_file(accompaniment_right_path, mono=True)

        # Create stereo AudioSegments
        vocal_segment = AudioSegment(np.array([vocal_l, vocal_r]), sr)
        accompaniment_segment = AudioSegment(np.array([acc_l, acc_r]), sr)

        # First pass: separate and analyze full track
        print("\nProcessing full stems...")
        separation_result = separator.separate_and_analyze(
            vocal_paths=(vocal_left_path, vocal_right_path),
            accompaniment_paths=(accompaniment_left_path, accompaniment_right_path),
            start_time=0.0,
            duration=full_duration,
            run_analysis=True
        )

        # Find best segments within the vocal portion
        print("\nAnalyzing segments...")
        vocal_track_for_segment_finding = separation_result.clean_vocal.slice(vocal_start, full_duration)
        backing_track_for_segment_finding = separation_result.separated_vocal.slice(vocal_start, full_duration)

        best_segments = find_best_segments(
            vocal_track=vocal_track_for_segment_finding,
            backing_track=backing_track_for_segment_finding,
            segment_length_sec=segment_length,
            hop_length_sec=segment_hop,
            config=config,
            top_k=top_k
        )

        # Analyze each best segment in detail
        segment_analyses = []
        for idx, seg in enumerate(best_segments):
            start_time = vocal_start + seg.time
            end_time = start_time + segment_length

            print(f"\nAnalyzing segment {idx + 1}/{len(best_segments)}")
            print(f"Time range: {start_time:.2f}s - {end_time:.2f}s")

            # Extract and analyze segment
            segment_result = separator.separate_and_analyze(
                vocal_paths=(vocal_left_path, vocal_right_path),
                accompaniment_paths=(accompaniment_left_path, accompaniment_right_path),
                start_time=start_time,
                duration=segment_length,
                run_analysis=True
            )

            # Detailed spectral analysis of segment
            analysis_path = analyzer.analyze(
                segment_result.clean_vocal,
                segment_result.separated_vocal
            )

            # Load and store analysis results
            with open(analysis_path / "analysis.json", 'r') as f:
                analysis_data = json.load(f)
                segment_analyses.append(SegmentAnalysis(
                    time_range=TimeRange(start=start_time, end=end_time),
                    metrics=seg,
                    spectral_analysis=analysis_data
                ))

        # Save consolidated results
        results_path = output_dir / "segment_analysis.json"
        with open(results_path, 'w') as f:
            json.dump({
                'config': {
                    'vocal_start': vocal_start,
                    'segment_length': segment_length,
                    'segment_hop': segment_hop,
                    'top_k': top_k
                },
                'segments': [asdict(s) for s in segment_analyses]
            }, f, indent=2)

        print(f"\nProcessing complete!")
        print(f"Separation results: {output_dir}/separation")
        print(f"Segment analysis: {results_path}")

        return separation_result, segment_analyses

    except Exception as e:
        print(f"Error during processing: {str(e)}")
        raise
