
##Notebook Generated by ChimeraCat

# Generated by ChimeraCat
#  /\___/\  ChimeraCat
# ( o   o )  Modular Python Fusion
# (  =^=  )
#  (______)  Generated: 2024-11-27 00:38:49
        # Compression Level: signatures
        
"""

Directory Structure:
stemprover\__init__.py
stemprover\analysis\base.py
stemprover\analysis\artifacts\base.py
stemprover\analysis\artifacts\high_freq.py
stemprover\analysis\artifacts\preprocessor.py
stemprover\analysis\artifacts\spectral.py
stemprover\analysis\selection\metrics.py
stemprover\analysis\selection\segment_finder.py
stemprover\analysis\selection\__init__.py
stemprover\common\audio_utils.py
stemprover\common\math_utils.py
stemprover\common\spectral_utils.py
stemprover\common\types.py
stemprover\common\__init__.py
stemprover\core\audio.py
stemprover\core\config.py
stemprover\core\types.py
stemprover\enhancement\base.py
stemprover\enhancement\controlnet.py
stemprover\enhancement\training.py
stemprover\io\audio.py
stemprover\preparation\base.py
stemprover\preparation\segments\generator.py
stemprover\preparation\segments\__init__.py
stemprover\separation\base.py
stemprover\separation\spleeter.py
stemprover\training\dataset.py
stemprover\training\pairs.py
tools\chimeracat.py
    
Module Dependencies:
graph-easy not found. Install with: cpan Graph::Easy
    
Import Summary:

    External Dependencies:
    abc, common.audio_utils, common.spectral_utils, common.types, core.audio, core.types, dataclasses, datetime, enum, json, librosa, matplotlib.pyplot as plt, numpy as np, pathlib, soundfile as sf, spleeter.separator, tensorflow as tf, torch, torch.nn as nn, torch.nn.functional as F, torch.utils.data, typing
    
    Internal Dependencies:
    ...common.audio_utils, ...common.math_utils, ...common.types, ...core.audio, ...core.types, ..analysis.spectral, ..core.audio, ..core.types, ..io.audio, .analysis.base, .analysis.phase, .analysis.spectral, .audio, .audio_utils, .base, .core.audio, .core.types, .diffusion.models, .diffusion.training, .math_utils, .metrics, .preparation.segments, .separation.base, .separation.spleeter, .spectral_utils, .types
    
    
# External imports
"""
import abc
import common.audio_utils
import common.spectral_utils
import common.types
import core.audio
import core.types
import dataclasses
import datetime
import enum
import json
import librosa
import matplotlib.pyplot as plt
import numpy as np
import pathlib
import soundfile as sf
import spleeter.separator
import tensorflow as tf
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data
import typing

# Combined module code


# From stemprover\__init__.py
"""Stemprover - audio stem separation enhancement tools"""

try:
    """from ._version import version as __version__  # Original relative import"""
except ImportError:
    __version__ = "unknown"

# Core imports
"""from .core.audio import AudioSegment  # Original relative import"""
"""from .core.types import (  # Original relative import"""
    ProcessingConfig,
    SeparationResult
)

# Separation components
"""from .separation.base import VocalSeparator  # Original relative import"""
"""from .separation.spleeter import SpleeterSeparator  # Original relative import"""

# Analysis components
"""from .analysis.base import VocalAnalyzer  # Original relative import"""
"""from .analysis.spectral import SpectralAnalyzer  # Original relative import"""
"""from .analysis.phase import PhaseAnalyzer  # Original relative import"""

# Future diffusion components
"""from .diffusion.models import PhaseAwareLoRA  # Original relative import"""
"""from .diffusion.training import PhaseAwareTrainer  # Original relative import"""

__all__ = [
    # Version
    '__version__',
    
    # Core
    'AudioSegment',
    'ProcessingConfig',
    'SeparationResult',
    
    # Separation
    'VocalSeparator',
    'SpleeterSeparator',
    
    # Analysis
    'VocalAnalyzer',
    'SpectralAnalyzer',
    'PhaseAnalyzer',
    
    # Diffusion
    'PhaseAwareLoRA',
    'PhaseAwareTrainer',
]

# From stemprover\analysis\base.py
from abc import ABC, abstractmethod
from pathlib import Path
"""from ..core.audio import AudioSegment  # Original relative import"""

class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\analysis\artifacts\base.py
"""from ...common.types import AudioArray, SpectrogramArray, TensorType  # Original relative import"""
"""from ...common.audio_utils import create_spectrogram  # Original relative import"""

from abc import ABC, abstractmethod
import numpy as np
import torch
import torch.nn as nn
from dataclasses import dataclass
    ... # Implementation details elided
def
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\analysis\artifacts\high_freq.py
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\analysis\artifacts\preprocessor.py
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\analysis\artifacts\spectral.py
from pathlib import Path
import json
import matplotlib.pyplot as plt
from typing import Dict
from datetime import datetime

"""from ...common.types import (  # Original relative import"""
    AudioArray, SpectrogramArray, FrequencyBands,
    DEFAULT_FREQUENCY_BANDS
)
"""from ...common.audio_utils import (  # Original relative import"""
    create_spectrogram, get_frequency_bins, get_band_mask
)
"""from ...common.math_utils import (  # Original relative import"""
    magnitude, angle, phase_difference, phase_coherence,
    rms, db_scale
)
"""from ...core.audio import AudioSegment  # Original relative import"""
"""from ...core.types import ProcessingConfig  # Original relative import"""

class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\analysis\selection\metrics.py
from dataclasses import dataclass

@dataclass
    ... # Implementation details elided

# From stemprover\analysis\selection\segment_finder.py
from dataclasses import dataclass
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\analysis\selection\__init__.py


# From stemprover\common\audio_utils.py
import numpy as np
import librosa
import soundfile as sf
"""from .types import AudioArray, SpectrogramArray, FrequencyBands  # Original relative import"""
"""from .math_utils import magnitude, angle, phase_difference, phase_coherence, rms  # Original relative import"""

def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\common\math_utils.py
import numpy as np
"""from .types import AudioArray, SpectrogramArray  # Original relative import"""

def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\common\spectral_utils.py
import numpy as np
import librosa
import soundfile as sf
from typing import Tuple
"""from .types import AudioArray, SpectrogramArray, FrequencyBand  # Original relative import"""
"""from .audio_utils import get_band_mask  # Original relative import"""

def
    ... # Implementation details elided

# From stemprover\common\types.py
from typing import Union, List, Dict, Optional, Tuple, Any
import numpy as np
import torch
import librosa


# Common type aliases
AudioArray = np.ndarray
SpectrogramArray = np.ndarray
TensorType = Union[torch.Tensor, np.ndarray]
FrequencyBand = Tuple[float, float]
FrequencyBands = Dict[str, FrequencyBand]


# Common constants
DEFAULT_FREQUENCY_BANDS: FrequencyBands = {
    "sub_bass": (20, 60),
    "bass": (60, 250),
    "low_mid": (250, 500),
    "mid": (500, 2000),
    "high_mid": (2000, 4000),
    "presence": (4000, 6000),
    "brilliance": (6000, 20000)
}

# From stemprover\common\__init__.py
"""from .types import (  # Original relative import"""
    AudioArray, SpectrogramArray, TensorType, 
    FrequencyBand, FrequencyBands, DEFAULT_FREQUENCY_BANDS
)
"""from .audio_utils import (  # Original relative import"""
    to_mono, create_spectrogram, get_frequency_bins, get_band_mask
)
"""from .math_utils import (  # Original relative import"""
    angle, magnitude, phase_difference, phase_coherence, rms, db_scale
)
"""from .spectral_utils import (  # Original relative import"""
    calculate_band_energy
)

# From stemprover\core\audio.py
from dataclasses import dataclass
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\core\config.py
from dataclasses import dataclass
    ... # Implementation details elided
class
    ... # Implementation details elided

# From stemprover\core\types.py
from dataclasses import dataclass
    ... # Implementation details elided
class
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\enhancement\base.py
from abc import ABC, abstractmethod
from typing import Optional
"""from ...core.audio import AudioSegment  # Original relative import"""
"""from ...core.types import ProcessingConfig  # Original relative import"""

class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\enhancement\controlnet.py
import torch
import torch.nn as nn
from typing import Optional, List, Tuple

class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\enhancement\training.py
from torch.utils.data import Dataset, DataLoader
import torch.nn.functional as F

class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\io\audio.py
from pathlib import Path
import numpy as np
import soundfile as sf
import librosa
from typing import Tuple
"""from ..core.audio import AudioSegment  # Original relative import"""

def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\preparation\base.py
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Tuple, Dict
"""from ..core.types import SeparationResult  # Original relative import"""
"""from ..core.audio import AudioSegment  # Original relative import"""

class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\preparation\segments\generator.py
from pathlib import Path
from typing import List, Tuple, Dict, Generator
from dataclasses import dataclass
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\preparation\segments\__init__.py


# From stemprover\separation\base.py
from dataclasses import dataclass
    ... # Implementation details elided
class
    ... # Implementation details elided
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\separation\spleeter.py
import tensorflow as tf
from pathlib import Path
import numpy as np
from typing import Dict, Tuple, Optional
from datetime import datetime
from spleeter.separator import Separator as SpleeterBase

"""from .base import VocalSeparator  # Original relative import"""
"""from ..core.audio import AudioSegment  # Original relative import"""
"""from ..core.types import SeparationResult  # Original relative import"""
"""from ..io.audio import load_audio_file, save_audio_file  # Original relative import"""
"""from ..analysis.spectral import SpectralAnalyzer  # Original relative import"""

class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
default().__enter__()
        
        config = tf.compat.v1.ConfigProto()
        config.gpu_options.allow_growth = True
        self.session = tf.compat.v1.Session(graph=self.graph, config=config)
        self.session.as_default().__enter__()
        
        # Initialize Spleeter only after graph/session setup
        self.separator = SpleeterBase('spleeter:2stems')

    def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
default().__exit__(None, None, None)
                self.session.close()
                delattr(self, 'session')
            
            if hasattr(self, 'graph'):
                self.graph.as_default().__exit__(None, None, None)
                delattr(self, 'graph')
            
        except Exception as e:
            print(f"Warning during cleanup: {str(e)}")

    @property
    def
    ... # Implementation details elided

# From stemprover\training\dataset.py
from torch.utils.data import Dataset, DataLoader
from typing import List, Dict, Path
"""from .core.types import ProcessingConfig, SegmentConfig  # Original relative import"""
"""from .preparation.segments import TrainingSegmentGenerator  # Original relative import"""
class
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided
def
    ... # Implementation details elided

# From stemprover\training\pairs.py
